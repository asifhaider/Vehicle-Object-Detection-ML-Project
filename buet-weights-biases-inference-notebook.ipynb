{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005387,"end_time":"2024-02-04T19:49:37.230543","exception":false,"start_time":"2024-02-04T19:49:37.225156","status":"completed"},"tags":[]},"source":["# Minimum Working Solution DL Engima 1.0"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.004526,"end_time":"2024-02-04T19:49:37.240361","exception":false,"start_time":"2024-02-04T19:49:37.235835","status":"completed"},"tags":[]},"source":["#### This notebook was inspired from [here](https://www.kaggle.com/code/sameen53/yolov8-minimum-working-sample)"]},{"cell_type":"markdown","metadata":{},"source":["Please upload the weights file in kaggle/working/ directory and run the code."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T19:49:37.251647Z","iopub.status.busy":"2024-02-04T19:49:37.251302Z","iopub.status.idle":"2024-02-04T19:49:38.000797Z","shell.execute_reply":"2024-02-04T19:49:37.999800Z"},"papermill":{"duration":0.758093,"end_time":"2024-02-04T19:49:38.003427","exception":false,"start_time":"2024-02-04T19:49:37.245334","status":"completed"},"tags":[]},"outputs":[],"source":["# basic libraries ...\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T19:49:38.015168Z","iopub.status.busy":"2024-02-04T19:49:38.014708Z","iopub.status.idle":"2024-02-04T19:49:52.478931Z","shell.execute_reply":"2024-02-04T19:49:52.477792Z"},"papermill":{"duration":14.472395,"end_time":"2024-02-04T19:49:52.481320","exception":false,"start_time":"2024-02-04T19:49:38.008925","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n"]}],"source":["# ultrlytics ...\n","\n","!pip install ultralytics -q --user"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T19:49:52.492883Z","iopub.status.busy":"2024-02-04T19:49:52.492556Z","iopub.status.idle":"2024-02-04T19:49:56.508875Z","shell.execute_reply":"2024-02-04T19:49:56.507885Z"},"papermill":{"duration":4.024653,"end_time":"2024-02-04T19:49:56.511131","exception":false,"start_time":"2024-02-04T19:49:52.486478","status":"completed"},"tags":[]},"outputs":[],"source":["# yolo ...\n","\n","# from ultralytics import YOLO\n","from ultralytics import RTDETR"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T19:50:41.202615Z","iopub.status.busy":"2024-02-04T19:50:41.201876Z","iopub.status.idle":"2024-02-04T19:50:41.206502Z","shell.execute_reply":"2024-02-04T19:50:41.205685Z"},"papermill":{"duration":0.014551,"end_time":"2024-02-04T19:50:41.208545","exception":false,"start_time":"2024-02-04T19:50:41.193994","status":"completed"},"tags":[]},"outputs":[],"source":["# model part ..."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T19:50:41.223222Z","iopub.status.busy":"2024-02-04T19:50:41.222892Z","iopub.status.idle":"2024-02-04T19:50:41.228801Z","shell.execute_reply":"2024-02-04T19:50:41.228101Z"},"papermill":{"duration":0.015396,"end_time":"2024-02-04T19:50:41.230731","exception":false,"start_time":"2024-02-04T19:50:41.215335","status":"completed"},"tags":[]},"outputs":[],"source":["# configuration file that tells YOLO where to find the dataset and what objects to detect ...\n","\n","file_content = \"\"\"\n","path: dhakaAI  # dataset root dir\n","train: train/images  # train images (relative to 'path')\n","val: train/images  # val images (relative to 'path')\n","\n","# Classes\n","names:\n","    0: auto_rickshaw\n","    1: bicycle\n","    2: bus\n","    3: car\n","    4: cart_vehicle\n","    5: construction_vehicle\n","    6: motorbike\n","    7: person\n","    8: priority_vehicle\n","    9: three_wheeler\n","    10: train\n","    11: truck\n","    12: wheelchair\n","\"\"\"\n","\n","with open(\"rtdetr.yaml\", mode=\"w\") as f:\n","    f.write(file_content)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T19:50:41.245279Z","iopub.status.busy":"2024-02-04T19:50:41.244963Z","iopub.status.idle":"2024-02-04T19:50:42.147496Z","shell.execute_reply":"2024-02-04T19:50:42.146601Z"},"papermill":{"duration":0.91209,"end_time":"2024-02-04T19:50:42.149614","exception":false,"start_time":"2024-02-04T19:50:41.237524","status":"completed"},"tags":[]},"outputs":[],"source":["# # Weights & Biases ...\n","\n","# import wandb\n","# wandb.init(mode=\"disabled\")"]},{"cell_type":"code","execution_count":8,"metadata":{"papermill":{"duration":34448.521058,"end_time":"2024-02-05T05:24:50.678618","exception":false,"start_time":"2024-02-04T19:50:42.157560","status":"completed"},"tags":[]},"outputs":[],"source":["# # yolov8 small model, configuration file and run the model in 3 epochs ... \n","\n","# # model = YOLO(\"yolov8s.pt\")\n","# # model.train(data=\"/kaggle/working/yolov8.yaml\", epochs=3)\n","\n","# # Load a COCO-pretrained RT-DETR-l model\n","# model = RTDETR('rtdetr-x.pt')\n","\n","# # Display model information (optional)\n","# model.info()\n","\n","# # Train the model on the COCO8 example dataset for 100 epochs\n","# results = model.train(data='/kaggle/working/yolov8.yaml', epochs=35, batch=8)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T05:25:01.827175Z","iopub.status.busy":"2024-02-05T05:25:01.826772Z","iopub.status.idle":"2024-02-05T05:25:01.831337Z","shell.execute_reply":"2024-02-05T05:25:01.830538Z"},"papermill":{"duration":5.763322,"end_time":"2024-02-05T05:25:01.833435","exception":false,"start_time":"2024-02-05T05:24:56.070113","status":"completed"},"tags":[]},"outputs":[],"source":["# inference part ..."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T05:25:12.665322Z","iopub.status.busy":"2024-02-05T05:25:12.664441Z","iopub.status.idle":"2024-02-05T05:28:26.976396Z","shell.execute_reply":"2024-02-05T05:28:26.975365Z"},"papermill":{"duration":203.405739,"end_time":"2024-02-05T05:28:30.764294","exception":false,"start_time":"2024-02-05T05:25:07.358555","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING ⚠️ best.pt appears to require 'dill', which is not in ultralytics requirements.\n","AutoInstall will run now for 'dill' but this feature will be removed in the future.\n","Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official YOLOv8 model, i.e. 'yolo predict model=yolov8n.pt'\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['dill'] not found, attempting AutoUpdate...\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ Command 'pip install --no-cache \"dill\" ' returned non-zero exit status 1.\n"]},{"name":"stderr","output_type":"stream","text":["885it [46:34,  3.16s/it]\n"]}],"source":["# get prediction boxes string according to the submission format ...\n","\n","# def get_prediction_string(boxes, scores, classes):\n","#     pred_strs = []\n","#     for i, score in enumerate(scores):\n","#         single_pred_str = \"\"\n","#         single_pred_str += str(float(classes[i])) + \" \" + str(float(score)) + \" \"\n","        \n","#         x_center , y_center, width,height = boxes[i]\n","#         x1 = float(x_center) - (float(width) / 2)\n","#         y1 = float(y_center) - (float(height) / 2)\n","#         width = float(width)\n","#         height = float(height)\n","#         #single_pred_str += \" \".join(str(float(x)) for x in boxes[i])\n","#         single_pred_str +=  f\"{x1} {y1} {width} {height}\"\n","        \n","#         pred_strs.append(single_pred_str)\n","#     ans = ','.join(map(str, pred_strs))\n","#     if len(ans):\n","#         return ans\n","# #     the solution metrics faield in case of a NaN, '' (empty). So, return \"0 0 0 0 0 0\" for NaN, '' (empty) string\n","#     return \"0 0 0 0 0 0\"\n","\n","# def get_prediction_string(boxes, scores, classes):\n","#     pred_strs = []\n","#     for i, score in enumerate(scores):\n","#         single_pred_str = \"\"\n","#         single_pred_str += str(float(classes[i])) + \" \" + str(float(score)) + \" \"\n","        \n","#         x_center , y_center, width,height = boxes[i]\n","#         x1 = float(x_center) - (float(width) / 2)\n","#         y1 = float(y_center) - (float(height) / 2)\n","#         x2 = float(x_center) + (float(width) / 2)\n","#         y2 = float(y_center) + (float(height) / 2)\n","#         #single_pred_str += \" \".join(str(float(x)) for x in boxes[i])\n","#         single_pred_str +=  f\"{x1} {y1} {width} {height}\"\n","        \n","#         pred_strs.append(single_pred_str)\n","#     ans = ','.join(map(str, pred_strs))\n","#     if len(ans):\n","#         return ans\n","# #     the solution metrics faield in case of a NaN, '' (empty). So, return \"0 0 0 0 0 0\" for NaN, '' (empty) string\n","#     return \"0 0 0 0 0 0\"\n","\n","# # get the predcition in id, ImageID, PredictionString_pred foramt ...\n","\n","# def get_prediction_entry(i, filename, boxes, scores, classes):\n","#     return {\n","#         \"id\": i, # strating from 0 ...\n","#         \"ImageID\": filename.split('.')[0], # before the extension ...\n","#         \"PredictionString_pred\": get_prediction_string(boxes, scores, classes)\n","#     }\n","\n","# # Directory path ...\n","# test_directory = \"custom_dataset\\images\\\\test\"\n","\n","# # Load the model ...\n","# # model = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n","# model = RTDETR(\"rtdetr\\\\results\\\\runs\\detect\\\\train\\weights\\\\best.pt\")\n","\n","\n","# # do the inference ...\n","\n","# def predict_all_files(test_directory):\n","#     predictions = []\n","#     for i,filename in tqdm(enumerate(os.listdir(test_directory))):\n","#         if filename.endswith(\".jpg\"):\n","#             filepath = os.path.join(test_directory, filename)\n","#             results = model.predict(source=filepath, conf=0.50, verbose=False)\n","#             boxes = results[0].boxes.xywhn\n","#             scores = results[0].boxes.conf\n","#             classes = results[0].boxes.cls\n","#             prediction = get_prediction_entry(i, filename, boxes, scores, classes)\n","#             predictions.append(prediction)\n","# #             to csv format ...\n","#     predictions_df = pd.DataFrame(predictions)\n","#     predictions_df.to_csv(\"submission.csv\", index=False)\n","\n","# # call the inference function ...\n","# predict_all_files(test_directory)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T05:28:42.025243Z","iopub.status.busy":"2024-02-05T05:28:42.024855Z","iopub.status.idle":"2024-02-05T05:28:42.052014Z","shell.execute_reply":"2024-02-05T05:28:42.051231Z"},"papermill":{"duration":5.828172,"end_time":"2024-02-05T05:28:42.054299","exception":false,"start_time":"2024-02-05T05:28:36.226127","status":"completed"},"tags":[]},"outputs":[],"source":["# load the submission dataframe ....\n","\n","# submission_df = pd.read_csv('submission.csv')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T05:28:52.960999Z","iopub.status.busy":"2024-02-05T05:28:52.960602Z","iopub.status.idle":"2024-02-05T05:28:52.973912Z","shell.execute_reply":"2024-02-05T05:28:52.973070Z"},"papermill":{"duration":5.565407,"end_time":"2024-02-05T05:28:52.975947","exception":false,"start_time":"2024-02-05T05:28:47.410540","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ImageID</th>\n","      <th>PredictionString_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>880</th>\n","      <td>880</td>\n","      <td>sylhet4_6903</td>\n","      <td>0.0 0.9468553066253662 0.6508529633283615 0.21...</td>\n","    </tr>\n","    <tr>\n","      <th>881</th>\n","      <td>881</td>\n","      <td>sylhet4_7198</td>\n","      <td>0.0 0.9511616826057434 0.5069331452250481 0.10...</td>\n","    </tr>\n","    <tr>\n","      <th>882</th>\n","      <td>882</td>\n","      <td>sylhet4_7257</td>\n","      <td>0.0 0.9549720287322998 0.5623467713594437 0.11...</td>\n","    </tr>\n","    <tr>\n","      <th>883</th>\n","      <td>883</td>\n","      <td>sylhet4_8142</td>\n","      <td>9.0 0.9560214281082153 0.3313125893473625 0.11...</td>\n","    </tr>\n","    <tr>\n","      <th>884</th>\n","      <td>884</td>\n","      <td>sylhet4_9027</td>\n","      <td>7.0 0.8953294157981873 0.034352146089076996 0....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id       ImageID                              PredictionString_pred\n","880  880  sylhet4_6903  0.0 0.9468553066253662 0.6508529633283615 0.21...\n","881  881  sylhet4_7198  0.0 0.9511616826057434 0.5069331452250481 0.10...\n","882  882  sylhet4_7257  0.0 0.9549720287322998 0.5623467713594437 0.11...\n","883  883  sylhet4_8142  9.0 0.9560214281082153 0.3313125893473625 0.11...\n","884  884  sylhet4_9027  7.0 0.8953294157981873 0.034352146089076996 0...."]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# preview ...\n","\n","# submission_df.tail()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T05:29:04.468439Z","iopub.status.busy":"2024-02-05T05:29:04.468023Z","iopub.status.idle":"2024-02-05T05:29:04.473926Z","shell.execute_reply":"2024-02-05T05:29:04.473073Z"},"papermill":{"duration":5.716935,"end_time":"2024-02-05T05:29:04.475946","exception":false,"start_time":"2024-02-05T05:28:58.759011","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(885, 3)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# dataframe shape ...\n","\n","# submission_df.shape"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T05:29:15.827574Z","iopub.status.busy":"2024-02-05T05:29:15.827201Z","iopub.status.idle":"2024-02-05T05:29:15.835633Z","shell.execute_reply":"2024-02-05T05:29:15.834767Z"},"papermill":{"duration":5.923038,"end_time":"2024-02-05T05:29:15.837459","exception":false,"start_time":"2024-02-05T05:29:09.914421","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["id                       0\n","ImageID                  0\n","PredictionString_pred    0\n","dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# any null value? ...\n","\n","# submission_df.isnull().sum()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T05:29:26.759103Z","iopub.status.busy":"2024-02-05T05:29:26.758724Z","iopub.status.idle":"2024-02-05T05:29:26.831927Z","shell.execute_reply":"2024-02-05T05:29:26.830914Z"},"papermill":{"duration":5.63123,"end_time":"2024-02-05T05:29:26.834375","exception":false,"start_time":"2024-02-05T05:29:21.203145","status":"completed"},"tags":[]},"outputs":[],"source":["# acceptable submission format ...\n","\n","# submission_df.to_csv('submission.csv',index=False)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T05:29:38.271305Z","iopub.status.busy":"2024-02-05T05:29:38.270932Z","iopub.status.idle":"2024-02-05T05:29:38.276782Z","shell.execute_reply":"2024-02-05T05:29:38.275846Z"},"papermill":{"duration":5.591344,"end_time":"2024-02-05T05:29:38.278727","exception":false,"start_time":"2024-02-05T05:29:32.687383","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["885it [00:00, 10757.84it/s]\n"]},{"data":{"text/plain":["['11 0.51796875 0.6532407407407408 0.46197916666666666 0.6453703703703704',\n"," '0 0.11614583333333334 0.5504629629629629 0.23229166666666667 0.44351851851851853',\n"," '9 0.26536458333333335 0.5115740740740741 0.0734375 0.2324074074074074',\n"," '3 0.078125 0.7384259259259259 0.15625 0.5157407407407407']"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# # make a dataframe with the actual labels\n","# test_directory = \"custom_dataset\\labels\\\\test\"\n","# actual_labels = []\n","\n","# for i,filename in tqdm(enumerate(os.listdir(test_directory))):\n","#     if filename.endswith(\".txt\"):\n","#         labels = []\n","#         filepath = os.path.join(test_directory, filename)\n","#         filename = filename.split('.')[0]\n","#         with open(filepath, \"r\") as f:\n","#             lines = f.readlines()\n","#             for line in lines:\n","#                 line = line.strip()\n","#                 labels.append(line)\n","#             # labels = str(labels)\n","#             actual_labels.append({\n","#                 \"ImageID\": filename,\n","#                 \"Label\": labels\n","#             })\n","\n","# actual_labels_df = pd.DataFrame(actual_labels)\n","\n","# # preview ...\n","# actual_labels_df.iloc[0].Label"]},{"cell_type":"code","execution_count":27,"id":"91d9f050","metadata":{},"outputs":[{"data":{"text/plain":["'11.0 0.9389405846595764 0.2792033702135086 0.3144342005252838 0.47266075015068054 0.6333363652229309,0.0 0.8431137800216675 -6.122887134552002e-05 0.32388001680374146 0.2343604564666748 0.43115460872650146,9.0 0.816709578037262 0.2295011319220066 0.40742557495832443 0.073573999106884 0.23297156393527985,11.0 0.7985581159591675 0.3246161863207817 0.28678280115127563 0.15672041475772858 0.18560791015625,3.0 0.5398489832878113 0.00037961453199386597 0.3987691104412079 0.1530478447675705 0.6009721159934998'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# submission_df.iloc[0].PredictionString_pred"]},{"cell_type":"code","execution_count":13,"id":"912413cb","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.1.18 🚀 Python-3.10.1 torch-2.1.2+cpu CPU (Intel Core(TM) i5-8250U 1.60GHz)\n","rt-detr-x summary: 642 layers, 65494151 parameters, 0 gradients, 222.5 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\labels... 2804 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2804/2804 [00:23<00:00, 117.75it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\144.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\145.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\146.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\147.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\148.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\150.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\151.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\153.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\154.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\155.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\156.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\157.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\158.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\159.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\160.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\161.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\162.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\163.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\164.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\166.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\167.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\168.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\169.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\170.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\171.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\172.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\173.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\174.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\175.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\176.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\178.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\179.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\180.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\181.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\182.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\183.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\184.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\185.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\186.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\187.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\189.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\190.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\191.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\192.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\Dipto_351.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\Dipto_352.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\Dipto_353.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\Dipto_360.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\Dipto_363.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\Dipto_364.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\images\\Dipto_366.jpg: corrupt JPEG restored and saved\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: F:\\Academics\\4-2\\CSE 472\\Project\\DLEnigma\\datasets\\dhakaAI\\train\\labels.cache\n"]},{"name":"stderr","output_type":"stream","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 351/351 [3:08:28<00:00, 32.22s/it]  \n"]},{"name":"stdout","output_type":"stream","text":["                   all       2804      13044       0.61      0.484      0.442      0.243\n","               bicycle       2804        459      0.612      0.266       0.29      0.108\n","                   bus       2804       3333      0.759      0.439       0.49      0.334\n","                   car       2804       5476       0.55      0.565      0.439       0.27\n","             motorbike       2804       2284      0.641      0.519      0.508      0.185\n","                 truck       2804       1492       0.49       0.63      0.484      0.317\n","Speed: 10.7ms preprocess, 3928.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"]}],"source":["model = RTDETR('results\\\\runs\\\\detect\\\\train\\weights\\\\best.pt')\n","results = model.val(data='rtdetr.yaml', batch=8)"]},{"cell_type":"code","execution_count":14,"id":"b9bbc0f8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'metrics/precision(B)': 0.6103293328018171, 'metrics/recall(B)': 0.4835799831685101, 'metrics/mAP50(B)': 0.4422619589646759, 'metrics/mAP50-95(B)': 0.24288680441661165, 'fitness': 0.2628243198714181}\n"]}],"source":["# save the results ...\n","print(results.results_dict)"]},{"cell_type":"code","execution_count":15,"id":"c6de1f0e","metadata":{},"outputs":[],"source":["# save the result dicts in a text file\n","with open(\"results_rtdetr.txt\", \"w\") as f:\n","    f.write(str(results.results_dict))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7527339,"sourceId":67836,"sourceType":"competition"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"},"papermill":{"default_parameters":{},"duration":34815.605722,"end_time":"2024-02-05T05:29:49.284153","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-04T19:49:33.678431","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}
